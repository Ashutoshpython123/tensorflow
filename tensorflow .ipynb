{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # DeepLearning with tensorflow basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset graph\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3,name='x')\n",
    "y = tf.Variable(4,name='y')\n",
    "f = x*x*y +y + 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_1:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Better way\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another better way\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "result    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.framework.ops.Graph object at 0x0000026D267EDD68>\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()\n",
    "\n",
    "print(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "    \n",
    "print(x2.graph is graph)  \n",
    "print(x2.graph is tf.get_default_graph())\n",
    "print(x1.graph is graph)\n",
    "print(x1.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LifeCycle Of a Node Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x + 3\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Run previous code efficiently\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y,z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n"
     ]
    }
   ],
   "source": [
    "zz = tf.square(y + z)\n",
    "with tf.Session() as s:\n",
    "    zz_v, y_v, z_v = s.run([zz,y,z])\n",
    "    print(zz_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using sklearn Elimination method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.21428571],\n",
       "       [1.07142857]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[1,5/3],[1,1/9]])\n",
    "y = np.array([[12/3],[21/9]])\n",
    "theta_best = np.linalg.inv(x.T.dot(x)).dot(x.T).dot(y)\n",
    "theta_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Normal equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.7465141e+01],\n",
       "       [ 4.3573415e-01],\n",
       "       [ 9.3382923e-03],\n",
       "       [-1.0662201e-01],\n",
       "       [ 6.4410698e-01],\n",
       "       [-4.2513184e-06],\n",
       "       [-3.7732250e-03],\n",
       "       [-4.2664889e-01],\n",
       "       [-4.4051403e-01]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate theta in tensorflow using normal equation\n",
    "# We will use housing dataset of end to end project\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m,1)),housing.data]\n",
    "x = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"x\" )\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(x)\n",
    "\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,x)),XT),y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_val = theta.eval()\n",
    "\n",
    "theta_val "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.00000000e+00  6.60969987e-17  5.50808322e-18  6.60969987e-17\n",
      " -1.06030602e-16 -1.10161664e-17  3.44255201e-18 -1.07958431e-15\n",
      " -8.52651283e-15]\n",
      "[ 0.38915536  0.36424355  0.5116157  ... -0.06612179 -0.06360587\n",
      "  0.01359031]\n",
      "0.11111111111111005\n",
      "(20640, 9)\n"
     ]
    }
   ],
   "source": [
    "# step -1 > Normalize the feature vector list using scikit-learn\n",
    "# step -2 > Gradient descent requires features vectors first\n",
    "# step -3 > We could do this using TF , But lets just use scikit-learn now\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar = StandardScaler()\n",
    "\n",
    "scaled_housing_data = scalar.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m,1)),scaled_housing_data]\n",
    "\n",
    "print(scaled_housing_data_plus_bias.mean(axis=0))\n",
    "print(scaled_housing_data_plus_bias.mean(axis=1))\n",
    "print(scaled_housing_data_plus_bias.mean())\n",
    "print(scaled_housing_data_plus_bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random_uniform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually Computing gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE= 9.161543\n",
      "Epoch 100 MSE= 8.805302\n",
      "Epoch 200 MSE= 8.464287\n",
      "Epoch 300 MSE= 8.137836\n",
      "Epoch 400 MSE= 7.8252635\n",
      "Epoch 500 MSE= 7.5259767\n",
      "Epoch 600 MSE= 7.239367\n",
      "Epoch 700 MSE= 6.964898\n",
      "Epoch 800 MSE= 6.7020135\n",
      "Epoch 900 MSE= 6.450213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.24162203],\n",
       "       [-0.21159671],\n",
       "       [ 0.03204535],\n",
       "       [-0.28414097],\n",
       "       [ 0.7851781 ],\n",
       "       [ 0.7133561 ],\n",
       "       [ 0.17435865],\n",
       "       [-0.23363025],\n",
       "       [ 0.08044434]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step-2 > Manually computing the gradient\n",
    "# the code is self explanatory except for a few new elements\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_epochs=1000\n",
    "learning_rate=0.01\n",
    "\n",
    "\n",
    "x = tf.constant(scaled_housing_data_plus_bias,dtype = tf.float32, name=\"x\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1,1],-1,1,seed = 42), name=\"theta\")\n",
    "\n",
    "y_pred = tf.matmul(x,theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error),name=\"mse\")\n",
    "\n",
    "gradient = 2/m * tf.matmul(tf.transpose(x),error)\n",
    "\n",
    "traning_op = tf.assign(theta, theta- learning_rate*gradient)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100==0:\n",
    "            print(\"Epoch\", epoch, \"MSE=\",mse.eval())\n",
    "            sess.run(traning_op)\n",
    "        best_theta = theta.eval()\n",
    "best_theta        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Using autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.999999999999787"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x*x*x\n",
    "\n",
    "x=100\n",
    "(f(x+.01)-f(x-.01))/.02\n",
    "\n",
    "def autodiff(f,x):\n",
    "    return (f(x+.01)-f(x-.01))/.02\n",
    "\n",
    "def cube(x):\n",
    "    return x*x*x\n",
    "\n",
    "def sq(x):\n",
    "    return x*x\n",
    "\n",
    "autodiff(sq,5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # lets us understand differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26d2c00bfd0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate x\n",
    "x = np.linspace(-10,10,100)\n",
    "\n",
    "# Compute y\n",
    "\n",
    "y = x * x\n",
    "\n",
    "plt.plot(x,y)\n",
    "\n",
    "# lets draw a tangent at x=0.5\n",
    "\n",
    "x0=5\n",
    "m = slope =2 * x0\n",
    "y1 = m * x-25\n",
    "plt.plot(x,y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # differentiate at a point using gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "x = tf.constant(5.0)\n",
    "y = tf.square(x)\n",
    "z = tf.gradients(y,x)\n",
    "\n",
    "with tf.Session() as s:\n",
    "    print(z[0].eval())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # compute gradients using autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = .01\n",
    "\n",
    "x = tf.constant(scaled_housing_data_plus_bias, dtype = tf.float32, name=\"x\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1,1,seed=42),name=\"theta\")\n",
    "\n",
    "y_pred = tf.matmul(x,theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = tf.gradients(mse,[theta])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch= 0 MSE= 9.161543\n",
      "Epoch= 100 MSE= 0.7145006\n",
      "Epoch= 200 MSE= 0.56670463\n",
      "Epoch= 300 MSE= 0.5555716\n",
      "Epoch= 400 MSE= 0.5488117\n",
      "Epoch= 500 MSE= 0.5436362\n",
      "Epoch= 600 MSE= 0.53962916\n",
      "Epoch= 700 MSE= 0.53650916\n",
      "Epoch= 800 MSE= 0.5340678\n",
      "Epoch= 900 MSE= 0.53214717\n",
      "Best theta :\n",
      "[[ 2.0685525 ]\n",
      " [ 0.8874027 ]\n",
      " [ 0.14401658]\n",
      " [-0.34770882]\n",
      " [ 0.36178368]\n",
      " [ 0.00393811]\n",
      " [-0.04269556]\n",
      " [-0.6614528 ]\n",
      " [-0.6375277 ]]\n"
     ]
    }
   ],
   "source": [
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 ==0:\n",
    "            print(\"Epoch=\", epoch, \"MSE=\",mse.eval())\n",
    "        sess.run(training_op)\n",
    "       \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta :\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # find partial derivative of complex function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(a,b):\n",
    "    z = 0\n",
    "    for i in range(100):\n",
    "        z = a * np.cos(z + i) + z * np.sin(b - i)\n",
    "        return z   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_func(2,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # gradient descent using this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "a = tf.Variable(2.0, name=\"a\")\n",
    "b = tf.Variable(4.0, name=\"b\")\n",
    "z = tf.constant(0.0,name=\"z0\")\n",
    "for i in range(100):\n",
    "    z = a * tf.cos(z + i) + z * tf.sin(b - i)\n",
    "    \n",
    "gradient = tf.gradients(z,[a,b])\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0089693\n",
      "[-1.4850847, -0.773633]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(z.eval())\n",
    "    print(sess.run(gradient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Implementing gradient descent using an GradientDescentoptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "x = tf.constant(scaled_housing_data_plus_bias, dtype = tf.float32, name=\"x\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(x, theta, name=\"prediction\")\n",
    "\n",
    "error = y_pred - y\n",
    "\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 MSE 9.161543\n",
      "Epoch : 100 MSE 0.7145006\n",
      "Epoch : 200 MSE 0.56670463\n",
      "Epoch : 300 MSE 0.5555716\n",
      "Epoch : 400 MSE 0.5488117\n",
      "Epoch : 500 MSE 0.5436362\n",
      "Epoch : 600 MSE 0.53962916\n",
      "Epoch : 700 MSE 0.53650916\n",
      "Epoch : 800 MSE 0.5340678\n",
      "Epoch : 900 MSE 0.53214717\n",
      "Best theta\n",
      "[[ 2.0685525 ]\n",
      " [ 0.8874027 ]\n",
      " [ 0.14401658]\n",
      " [-0.34770882]\n",
      " [ 0.36178368]\n",
      " [ 0.00393811]\n",
      " [-0.04269556]\n",
      " [-0.6614528 ]\n",
      " [-0.6375277 ]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch :\", epoch, \"MSE\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "     \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta\")   \n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Implementing Gradient Descent using MomemtumOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = .01\n",
    "\n",
    "x = tf.constant(scaled_housing_data_plus_bias, dtype = tf.float32, name=\"x\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(x, theta, name=\"production\")\n",
    "\n",
    "error = y_pred - y\n",
    "\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate = learning_rate, momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Theta\n",
      "[[ 2.068558  ]\n",
      " [ 0.8296286 ]\n",
      " [ 0.11875337]\n",
      " [-0.26554456]\n",
      " [ 0.3057109 ]\n",
      " [-0.00450251]\n",
      " [-0.03932662]\n",
      " [-0.89986444]\n",
      " [-0.87052065]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "print(\"Best Theta\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # placeholder nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n",
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "A = tf.placeholder(tf.float32, shape=(None,3))\n",
    "B = A + 5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    B_value_1 = B.eval(feed_dict = {A: [[1,2,3]]})\n",
    "    B_value_2 = B.eval(feed_dict = {A: [[4,5,6],[7,8,9]]})\n",
    "    \n",
    "print(B_value_1)    \n",
    "print(B_value_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # mini batch gradient descent using placeholder nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, n +1), name = \"x\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n +1,1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(x, theta, name=\"prediction\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "\n",
    "training_op = optimizer.minimize(mse)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs =10\n",
    "m = housing.target.shape[0]\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)\n",
    "    indices = np.random.randint(m, size = batch_size)\n",
    "    x_batch = scaled_housing_data_plus_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1,1)[indices]\n",
    "    return x_batch,y_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.        , -0.43635204,  0.50539419, -0.55697891, -0.03498224,\n",
       "          0.39253765,  0.14136418, -0.80147053,  0.67867026],\n",
       "        [ 1.        ,  0.6177724 , -1.87834817,  0.36763443,  0.05194415,\n",
       "          1.9820333 ,  0.01268926,  0.99636589, -0.93352196],\n",
       "        [ 1.        ,  0.07465565,  1.85618152, -0.42575976, -0.28273636,\n",
       "         -0.39337964, -0.06093361, -0.56737725, -0.07501712]]), array([[1.173],\n",
       "        [1.948],\n",
       "        [2.61 ]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_batch(1,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0703337 ],\n",
       "       [ 0.8637145 ],\n",
       "       [ 0.12255151],\n",
       "       [-0.31211874],\n",
       "       [ 0.38510373],\n",
       "       [ 0.00434168],\n",
       "       [-0.01232954],\n",
       "       [-0.83376896],\n",
       "       [-0.8030471 ]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is execution phase\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            x_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict = {x: x_batch, y: y_batch})\n",
    "            \n",
    "    best_theta = theta.eval()\n",
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch =  0 MSE =  9.161543\n",
      "Epoch =  100 MSE =  0.7145006\n",
      "Epoch =  200 MSE =  0.56670463\n",
      "Epoch =  300 MSE =  0.5555716\n",
      "Epoch =  400 MSE =  0.5488117\n",
      "Epoch =  500 MSE =  0.5436362\n",
      "Epoch =  600 MSE =  0.53962916\n",
      "Epoch =  700 MSE =  0.53650916\n",
      "Epoch =  800 MSE =  0.5340678\n",
      "Epoch =  900 MSE =  0.53214717\n"
     ]
    }
   ],
   "source": [
    "# lets save a model\n",
    "# code for gradient descent optimizer\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "x = tf.constant(scaled_housing_data_plus_bias, dtype = tf.float32, name=\"x\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(x, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch = \", epoch, \"MSE = \",mse.eval())\n",
    "            save_path = saver.save(sess, \"model1_ckps/first_model.ckpt\")\n",
    "        sess.run(training_op)\n",
    "     \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"model1_ckps/last_model.ckpt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685525 ],\n",
       "       [ 0.8874027 ],\n",
       "       [ 0.14401658],\n",
       "       [-0.34770882],\n",
       "       [ 0.36178368],\n",
       "       [ 0.00393811],\n",
       "       [-0.04269556],\n",
       "       [-0.6614528 ],\n",
       "       [-0.6375277 ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Restoring models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model1_ckps/last_model.ckpt\n",
      "[[ 2.0685525 ]\n",
      " [ 0.8874027 ]\n",
      " [ 0.14401658]\n",
      " [-0.34770882]\n",
      " [ 0.36178368]\n",
      " [ 0.00393811]\n",
      " [-0.04269556]\n",
      " [-0.6614528 ]\n",
      " [-0.6375277 ]]\n"
     ]
    }
   ],
   "source": [
    "# Restore model\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"model1_ckps/last_model.ckpt\")\n",
    "    best_theta_restored = theta.eval()\n",
    "    print(best_theta_restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check restored theta is same as saved theta\n",
    "\n",
    "np.allclose(best_theta,best_theta_restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default saver will save and restored all variables under their own name.\n",
    "# if you need more control then -\n",
    "# the following saver will save and restore only the theta variable under their own name weight.\n",
    "\n",
    "saver = tf.train.Saver({'weight':theta})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # step-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir =\"{}/run-{}/\".format(root_logdir,now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini Batch Gradient Descent\n",
    "\n",
    "n_epochs=1000\n",
    "learning_rate=0.01\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None,n+1), name=\"x\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0, seed=42),name=\"theta\")\n",
    "y_pred = tf.matmul(x,theta, name=\"prediction\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # step-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a node in the graph that will evaluate the mse\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE',mse)\n",
    "\n",
    "# create a filewriter\n",
    "\n",
    "filewriter = tf.summary.FileWriter(logdir,tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of batches\n",
    "\n",
    "n_epochs=10\n",
    "batch_size=100\n",
    "n_batches = int(np.ceil(m/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the execution phase\n",
    "# evaluate the mse_summary node regularly during training\n",
    "# and write the summary for even file\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            x_batch,y_batch = fetch_batch(epoch,batch_index,batch_size)\n",
    "            if batch_index % 10 ==0:\n",
    "                summary_str = mse_summary.eval(feed_dict={x:x_batch,y:y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                filewriter.add_summary(summary_str,step)\n",
    "            sess.run(training_op, feed_dict={x : x_batch, y : y_batch})\n",
    "    best_theta = theta.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "filewriter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0703337 ],\n",
       "       [ 0.8637145 ],\n",
       "       [ 0.12255151],\n",
       "       [-0.31211874],\n",
       "       [ 0.38510373],\n",
       "       [ 0.00434168],\n",
       "       [-0.01232954],\n",
       "       [-0.83376896],\n",
       "       [-0.8030471 ]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
